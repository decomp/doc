\begin{abstract}
% * Summary of the _entire_ report.
% * Must be 150-300 words
% * Puts your work in context, how it was carried out and what its major
%   successes/conclusions were
%    - Not a contents list
%    - Don't use acronyms unless well-understood
% * Must be able to stand entirely on its own

% === [ Keywords ] ===
%
%    * Decompilation
%
%    * Composition
%    * Decompilation pipeline
%    * Stages
%    * Language-agnostic
%
%    * LLVM IR
%    * Control flow primitives
%    * Subgraph isomorphism search
%    * Control flow analysis
%    * Recover / reconstruct
%    * Basic block

% --- [ Background and purpose ] -----------------------------------------------

% * What you set out to do and why
% * Why is this interesting?

Decompilation or reverse compilation is the process of translating low-level machine-readable code into high-level human-readable code. Due to the amount of information lost in the compilation process

The problem is complex as much information is lost during the compilation process and decompilers often rely on inference to recover high-level control flow primitives and expressions from low-level code.

% TODO: Make shorter.

A dynamic approach to problem solving is the composition of independent and specialized components which communicate using well-defined interfaces. Several smaller components may conceptually be arranged in a pipeline of stages which transform, massage or interpret the input in a certain way to solve larger tasks. Systems which expose their individual components to end-users facilitate dynamic workflows, as they enable users to adapt and extend each part of the system. Meanwhile, the monolithic nature of most production-quality decompilers prevents reverse engineers from utilizing such workflows and may leave them with scripting and plugin support as a substitute. This report explores the potential of a decompilation pipeline which exposes its components to the end-user. A core focus is the language-agnostic aspects of composition, such that the various components may be written in any programming language and utilized by other projects.

% The intention is to expose the individual components of the decompilation pipeline to the end-user, who may for each subproblem select between a variety of components with their individual advantages and limitations.

% --- [ Methodology/design ] ---------------------------------------------------

The decompilation pipeline consists of several components which are conceptually grouped into three modules. The front-end module translates a source language (e.g. x86 Assembly) into LLVM IR; a platform-independent low-level intermediate representation. The middle-end identifies high-level control flow primitives (e.g. 2-way conditionals, pre-test loops) in the LLVM IR. The back-end uses this information to translate the LLVM IR into a high-level target programming language (Go).

% The control flow analysis component of the decompiler pipeline utilizes subgraph isomorphism search algorithms to identify and reconstruct high-level control flow primitives from LLVM IR, which is a platform-independent low-level intermediate representation used by the LLVM compiler framework.

The control flow analysis operates directly on graphs and is not dependent on either LLVM IR or

% --- [ Results ] --------------------------------------------------------------

% * What you found

The decompilation pipeline is composed of independent components and has been proven capable of recovering nested pre-test and post-test loops (e.g. while, do-while), and 1-way and 2-way conditionals (e.g. if, if-else) from LLVM IR.

A post-processing stage deals with language-specific features

Each stage of the pipeline is extensible; and in practise it took less than 3 hours to extend the post-processing stage to simplify the loop-header of pre-test loops (from init;while(cond){post} to for(init; cond; post)) by locating surrounding initialization and post-statements

Each stage of the decompilation pipeline is easily extensible. For example the post-processing stage was extended to simplify pre-test loops by locating the initialization and post-statement

The decompiler pipeline has proven easily extensible and flexible. It is capable of recovering nested pre-test loops, 2-way conditionals,

%As an example, building upon the existing infrastructure and extending the post-translation source code cleanup; it took less than three hours to implement a source code translation rule which propagates initialization and post-statements of for-loops

%from the block statments to the for-loop header.

%The decompiler pipeline successfully identifies and recovers high-level reconstructed smaller

% --- [ Future work ] ----------------------------------------------------------

% * (recommendations)

There exists huge potential for future development. Investigate adding further post-processing stages to make the Go output more idiomatic; e.g. the \texttt{grind} tool by Russ Cox moves variable declarations closer to their usage. Finish developing the LLVM IR library and replace the C++ binding with a pure Go implementation; consider \texttt{llgo} a potential future user. Validate the language-agnostic aspects of the design by implementing components in other languages; e.g. data flow analysis in Haskell. Verify that the middle-end handles decompilation heavy-lifting (i.e. control flow analysis, data flow analysis) by implementing additional back-ends (e.g. Python output).

\end{abstract}
