% --- [ Performance ] ----------------------------------------------------------

\subsection{Performance}

The performance characteristics of the various components have been considered during every stage of the development process, but the initial prototypes have prioritized correctness and simplicity over performance. These prototypes have aimed at identifying suitable data structures and algorithms for the problems, through iterative redesigns and reimplementations. Once the major design decisions stabilized, production quality prototypes were being developed and thoroughly tested. To limit the risk of premature optimizations, micro-level performance work was intentionally postponed to the later stages of development.

Components with straight forward implementations (e.g. the LLVM IR library) have been profiled to identify performance bottle necks, as further described in section \ref{sec:ver_profiling}. When estimating the time complexity of various subgraph isomorphism search algorithms however, algorithm research and the use of intuition proved far more valuable. One of the first throw-away prototypes provided a partial implementation of the subgraph isomorphism algorithm proposed by Ullman. After further research the prototype was eventually discarded as the Ullman algorithm had been proven to scale poorly for randomly connected graphs with more than 700 nodes \cite{iso_performance_comparison}. To put this into perspective, the \texttt{main} function of the c4\footnote{C in four functions: \url{https://github.com/rswier/c4}} compiler consists of 248 basic blocks; in other words, the CFG of the \texttt{main} function is a connected graph (every node is reachable from the entry node) with 248 nodes. This leaves a margin (for the number of basic blocks in functions) of less than an order of magnitude before the Ullman algorithm starts to perform poorly.

There exist several subgraph isomorphism algorithms which scale better than the Ullman algorithm for graphs with a large number of nodes; such as the VF2 algorithm for dense graphs and McKay's nauty algorithm for sparse graphs \cite{iso_performance_comparison,subgraph_isomorphism_algorithms}. In the case of the c4 compiler, the CFGs are sparse with $ 1.35 $ edges per node in average, which would favour the nauty algorithm. The specific properties of CFGs (e.g. sparse connected graphs) guided the design of the subgraph isomorphism search algorithm, as further described in section \ref{sec:impl_subgraph_isomorphism_search_library}.

To stress test the implementation of the decompilation components and to get an estimate of their time complexities, a set of C programs were automatically generated\footnote{Generate nested C programs: \url{https://gist.github.com/mewmew/677994ee8da60bee1de9}} with $ 2^{x} $ nested \texttt{if}-statements (where $ 7 \le x \le 12 $). These C programs were converted to LLVM IR and decompiled into Go using the same steps as described in appendix \ref{app:clang_example}, \ref{app:control_flow_graph_generation_example}, \ref{app:restructure_example}, \ref{app:code_generation_example} and \ref{app:post-processing_example}. The time complexity of each step may be estimated by monitoring how the execution time changes with regards to $ n $, where $ n $ represents the number of nodes in the CFG of the generated programs; as summarized in table \ref{tbl:run_time_summary}. The CFG of each generated program contains exactly twice as many nodes as nested \texttt{if}-statements; i.e. $ n = 2^{x+1} $.

% TODO: Fill in the remaining run times for each component.

\begin{table}[htbp]
	\begin{center}
		\begin{tabular}{|l|l|l|l|l|l|l|}
			\hline
			Component & $ n = 256 $ & $ n = 512 $ & $ n = 1024 $ & $ n = 2048 $ & $ n = 4096 $ & $ n = 8192 $ \\
			\hline
			%      1.14s ( 0m01.135s,  0m01.168s,  0m01.114s)
			%      4.01s ( 0m04.060s,  0m04.059s,  0m03.897s)
			%     15.27s ( 0m15.057s,  0m15.714s,  0m15.038s)
			%     58.51s ( 0m59.168s,  0m59.675s,  0m56.698s)
			%  3m 55.84s ( 3m59.045s,  3m53.217s,  3m55.250s)
			% 15m 43.88s (15m40.832s, 15m42.877s, 15m47.934s)
			\rowcolor{light_green_3}
			\texttt{ll2dot} & 1.14s & 4.01s & 15.27s & 1m 0.25s & 3m 55.84s & 15m 43.88s \\
			%      0.97s ( 0m00.974s)
			%      4.37s ( 0m04.370s)
			%     21.37s ( 0m21.374s)
			%  2m  6.34s ( 2m06.344s)
			% 11m  0.56s ( 11m0.555s)
			% 85m 58.35s (85m58.345s)
			\rowcolor{light_green_3}
			\texttt{restructure} & 0.97s & 4.37s & 21.37s & 2m 6.34s & 11m 0.56s & 85m 58.35s \\
			%      2.85s ( 0m02.849s)
			%     10.59s ( 0m10.587s)
			%     40.95s ( 0m40.946s)
			%  2m 41.42s ( 2m41.417s)
			% 10m 46.56s (10m46.562s)
			% foo
			\rowcolor{light_green_3}
			\texttt{ll2go} & 2.85s & 10.59s & 40.95s & 2m 41.42s & 10m 46.56s & 12 \\
			\hline
			\multicolumn{7}{|l|}{\texttt{go-post}} \\
			\hline
			\rowcolor{light_green_3}
			\textit{unresolved} & 7 & 8 & 9 & 10 & 11 & 12 \\
			\rowcolor{light_green_3}
			\textit{mainret} & 7 & 8 & 9 & 10 & 11 & 12 \\
			\rowcolor{light_red_3}
			\textit{localid} & 7 & 8 & 9 & 10 & 11 & 12 \\
			\rowcolor{light_green_3}
			\textit{assignbinop} & 7 & 8 & 9 & 10 & 11 & 12 \\
			\rowcolor{light_green_3}
			\textit{deadassign} & 7 & 8 & 9 & 10 & 11 & 12 \\
			\rowcolor{light_green_3}
			\textit{forloop} & 7 & 8 & 9 & 10 & 11 & 12 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{The first column specifies the component being tested, and each consecutive column presents the execution time of the component (based on the average of three consecutive runs) in relation to $ n $, which represents the number of nodes in the CFG. Each row below the \texttt{go-post} component represents a specific post-processing rewrite rule (e.g. \textit{mainret}), as further described in appendix \ref{app:post-processing_example}. The steps which execute in polynomial time with regards to $ n $ have been highlighted in green, while the steps which execute in exponential time with regards to $ n $ have been highlighted in red.}
	\label{tbl:run_time_summary}
\end{table}

Each step of the decompilation pipeline completed in resonable time (i.e. polynomial time with regards to $ n $) except for one, namely the \textit{``localid''} rewrite rule (see figure \ref{fig:rewrite_3} of appendix \ref{app:post-processing_example}) of the post-processing stage. As discussed in section \ref{sec:evaluation}, most of the post-processing rewrite rules are considered experimental and the \textit{``localid''} rewrite rule suffers from both inaccuracy and performance issues. The \textit{``localid''} rewrite rule optionally provides rudamentary expression propagation support, and will be removed when proper data flow analysis has been implemented by the middle-end (see section \ref{sec:con_design_validation}).

As the size of $ n $ doubles in table \ref{tbl:run_time_summary}, the execution time of \texttt{ll2dot} roughly quadruples. The time complexity of \texttt{ll2dot} is therefore estimated to be $ \Omega(n^{2}) $. Please note that this may not hold true for larger values of $ n $, as a formal time complexity analysis of the algorithm is yet to be conducted. Similarly, as the size of $ n $ double, the execution time of \texttt{restructure} roughly octuples. The time complexity of \texttt{restructure} is therefore estimated to be $ \Omega(n^{3}) $. The same logic and caveats may be applied to the other components to estimate their time complexities; a summary of which is presented below.

% TODO: Add the time complexity estimates for the remaining components.

\begin{itemize}
	\item \texttt{ll2dot}: $ \Omega(n^{2}) $
	\item \texttt{restructure}: $ \Omega(n^{3}) $
	\item \texttt{ll2go}: $ \Omega(n^{2}) $
	\item \texttt{go-post}
	\begin{itemize}
		\item \textit{unresolved}: foo
		\item \textit{mainret}: foo
		\item \textit{localid}: foo
		\item \textit{assignbinop}: foo
		\item \textit{deadassign}: foo
		\item \textit{forloop}: foo
	\end{itemize}
\end{itemize}

In summary, profiling is great for optimizing the implementations of simple problems. Algorithm research, runtime complexity theory and intuition is essential for implementing performant solutions for complex problems. Furthermore, knowledge about specific properties of the problem may be exploited to design performant algorithms.

% --- [ Subsubsections ] -------------------------------------------------------

\input{sections/8_verification/2_performance/1_profiling}
\input{sections/8_verification/2_performance/2_benchmarks}
