% --- [ Security Assessment ] --------------------------------------------------

\subsection{Security Assessment}
\label{sec:ver_security_assessment}

To assess the security of the decompiler pipeline, lets imagine a scenario in which users are given access to the implementation details and source code of the entire system and may provide arbitrary input to any of its components. A potential scenario could involve a web site which provides decompilation as a service and allows its users to interact with the various stages of the decompiler pipeline. The Retargetable Decompiler provides such a service, except it only allows users to interact with the binary analysis stage of the pipeline (see section \ref{sec:lit_review_binary_analysis}) and its source code is proprietary. The scope of this security assessment will be limited to the various components of the decompiler pipeline and their interaction. In particular security issues related to the operating system, network stack, web server and web site (e.g. SQL-injection and XSS vulnerabilities) of the decompilation service are intentionally excluded from the scope of the security assessment.

The objective of an attacker may be to escalate their privileges in a system by exploiting it to execute actions not intended by design. Since the security of any system is only as strong as its weakest link, it is critical to identify and isolate likely targets for attacks. Projects which consist of or depend on large C or C++ code bases may exhibit memory safety issues, such as buffer overflows or use-after-free vulnerabilities. These issues are considered low-hanging fruit for attackers and have a long history of successful exploitation \cite{for_fun_and_profit}. Several modern programming languages (including Go) provide memory safety guarantees and may solve these issues by inserting bounds-checking for array accesses and using garbage collection for memory management. Code written in memory safe languages may still contain other security vulnerabilities caused by logic errors or insufficient validation, sanitation and parametrization of input (e.g. command injection and directory traversal vulnerabilities).

The number of lines of code in a project may give an indication to the project's complexity and to some extent its potential attack surface. As summarized in table \ref{tbl:loc_summary} every component of the decompiler pipeline except \texttt{restructure} depends on LLVM. The LLVM code base contains approximately 800~000 lines of C++ source code, and even if only a portion of the code will be linked into the executables it is an interesting target for attacks. One thing to keep in mind is that there are several high-end users of the LLVM project (such as Apple, Intel, NVIDIA and Sony \cite{llvm_users}) and it has a well established code reviewing process. Some of the LLVM developers are also very well educated in common security vulnerabilities and have developed the Clang Static Analyzer, which is a static source code analysis tool that locates bugs (such as buffer overflows and use-after-free issues) in C and C++ programs \cite{clang_analyzer}. The LLVM project may contain several security issues due to its size, but they are most likely difficult to discover since the low-hanging fruit have been caught already by the Clang Static Analyzer. Similarly, Google Protocol Buffers are used extensively by several companies and organizations and the likelyhood of discovering a simple security vulnerability in its code base is low.

\begin{table}[htbp]
	\begin{center}
		\begin{tabular}{|l|l|l|l|}
			\hline
			\textbf{Project} & \textbf{Language} & \textbf{Lines} & \textbf{Dependencies} \\
			\hline
			\multicolumn{4}{|l|}{\hspace{4ex} \textit{Front-end}} \\
			\hline
			Dagger & C++ & 2~000 & LLVM \\
			Fracture & C++ & 20~000 & LLVM \\
			MC-Semantics & C++ & 25~000 & LLVM and Google Protocol Buffers \\
			\hline
			\multicolumn{4}{|l|}{\hspace{4ex} \textit{Middle-end}} \\
			\hline
			ll2dot & Go & 500 & LLVM and dot \\
			restructure & Go & 300 & graphs and dot \\
			\hline
			\multicolumn{4}{|l|}{\hspace{4ex} \textit{Back-end}} \\
			\hline
			ll2go & Go & 1~500 & LLVM and llvm (Go) \\
			go-post & Go & 3~000 & - \\
			\hline
			\multicolumn{4}{|l|}{\hspace{4ex} \textit{Dependencies}} \\
			\hline
			LLVM & C++ & 800~000 & - \\
			Google Protocol Buffers & C++ & 125~000 & - \\
			dot & Go & 7~000 & - \\
			llvm (Go) & Go & 5~000 & - \\
			graphs & Go & 2~000 & - \\
			\hline
		\end{tabular}
	\end{center}
	\caption{A rough summary of each project specifying their programming language, total number of lines of code and dependencies.}
	\label{tbl:loc_summary}
\end{table}

There are still three potential targets which may contain memory related vulnerabilities, namely the front-end projects which translate binary executables, object code and shared libraries to LLVM IR. Insufficient validation during the parsing of headers (e.g. trusting the values of section header fields in ELF files) may lead to security vulnerabilities. The front-end projects rely extensively on parsing logic for the binary analysis stage (see section \ref{sec:lit_review_binary_analysis}), and are therefore susceptible to security vulnerabilities.

The security implications of various design decisions have been taken into consideration during the development process of the Go components. The Go runtime guarantees memory safety by inserting bounds-checking for array accesses and using garbage collection for memory management. Furthermore, the Go project focuses on addressing security issues at the language-level rather than relying on security through obscurity (e.g. address space layout randomization) to mitigate these issues at the OS-level, as further explained and justified by the quote of Russ Cox (who works on the Go compiler and runtime) presented in figure \ref{fig:no_aslr}.

\begin{figure}[htbp]
	\begin{quote}
		\textit{``Address space randomization is an OS-level workaround for a language-level problem, namely that simple C programs tend to be full of exploitable buffer overflows.  Go fixes this at the language level, with bounds-checked arrays and slices and no dangling pointers, which makes the OS-level workaround much less important.  In return, we receive the incredible debuggability of deterministic address space layout.  I would not give that up lightly.''}
	\end{quote}
	\caption{Reply by Russ Cox to a discussion regarding ASLR, on the Go mailing list\protect\footnotemark.}
	\label{fig:no_aslr}
\end{figure}
\footnotetext{Secure Go binaries: \url{https://groups.google.com/d/msg/golang-nuts/Jd9tlNc6jUE/6dLasvOs4nIJ}}

There is one know issue with the Go bindings for LLVM IR which may compromise the integrity of the output from the decompilation pipeline. The \texttt{ll2dot} and \texttt{ll2go} components require access to the names of unnamed basic blocks, but these names are not accessible from the API of the LLVM IR library as they are generated on the fly by the assembly printer. As a work around, the debug facilities of the LLVM IR library have been utilized to print the assembly to temporary files, which are parsed to gain access to the names of unnamed basic blocks. These temporary files may be tampered with, if not sufficiently protected by access permissions, which may compromise the integrity of the control flow analysis stage. A pure Go library for interacting with LLVM IR is being developed (see section \ref{sec:impl_llvm_ir_library}) which will include native support for calculating the names of unnamed basic blocks, thus mitigating this security issue.

To conclude, the security assessment was conducted to identify potential security issues and provide an intuition for the general security of the decompilation system. In scenarios such as the one described above (i.e. users may provide arbitrary input), it is advisable to further harden the decompilation system by utilizing defence in depth (i.e. several independent layers of security) and the principle of least privilege (e.g. use jails in FreeBSD and LXC in Linux).
